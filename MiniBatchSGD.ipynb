{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9f29c0321613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### ANN ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiniBatchSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'learning_rate'"
     ]
    }
   ],
   "source": [
    "#### ANN ####\n",
    "ann = MiniBatchSGD(learning_rate=0.25, momentum=0.0001)\n",
    "ann.add_input(len(train_data[0]))\n",
    "ann.add_layer(size=30)\n",
    "ann.add_layer(size=20)\n",
    "ann.add_layer(size=10)\n",
    "\n",
    "ann.fit(train_data, target_data, epochs, batch_size)\n",
    "scores = ann.evaluate(test_data, test_target)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron  0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Neuron  1\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "batch finished!\n",
      "Neuron  2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "batch finished!\n",
      "epoch finished!!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#### ANN ####\n",
    "trainData=[[1,2,3,4], [5,6,7,8], [0,0,0,0]]\n",
    "targetData=[0,0,1]\n",
    "testData=[1,5]\n",
    "testTarget=[2,6]\n",
    "ann = MiniBatchSGD(learningRate=0.25, momentum=0.0001)\n",
    "ann.add_input(len(train_data[0]))\n",
    "#ann.add_layer(size=30)\n",
    "#ann.add_layer(size=20)\n",
    "#ann.add_layer(size=10)\n",
    "\n",
    "ann.fit(trainData, targetData, batchSize=2)\n",
    "scores = ann.evaluate(testData, testTarget)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Feed Forward\n",
      "None\n",
      "0\n",
      "Feed Forward\n",
      "None\n",
      "0\n",
      "Feed Forward\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "neuronList = []\n",
    "neuronList.append(Neuron())\n",
    "neuronList.append(Neuron())\n",
    "neuronList.append(Neuron())\n",
    "\n",
    "for neuron in neuronList:\n",
    "    print(neuron.value)\n",
    "    print(neuron.feed_forward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchSGD:\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def __init__(self, learningRate=0.25, momentum=0.01):\n",
    "        self.learningRate = learningRate\n",
    "        self.momentum = momentum\n",
    "        self.layers = []\n",
    "        self.neuronList = []\n",
    "        self.numLayer = 0\n",
    "        \n",
    "    # Belum Selesai\n",
    "    def add_input(self, inputDim):\n",
    "        self.inputDim = inputDim\n",
    "        self.add_layer(inputDim)\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def add_layer(self, size):\n",
    "        \n",
    "        layer = []\n",
    "        for i in range(0, size):\n",
    "            layer.append(Neuron())\n",
    "        self.neuronList.append(layer)\n",
    "        \n",
    "        self.numLayer = self.numLayer + 1\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def fit(self, data, target, epochs=1, batchSize=10):\n",
    "        \n",
    "        # Dapat dioptimasi dengan pemodelan matematika yang lebih baik\n",
    "        # iterasi epoch\n",
    "        for i in range(0,epochs):\n",
    "            # iterasi batch\n",
    "            for j in range(0,len(data),batchSize):\n",
    "                \n",
    "                # inisialisasi menjadi 2d dengan nilai 0*\n",
    "                lgList = []\n",
    "                \n",
    "                # iterasi data\n",
    "                for k in range(j,j+batchSize):\n",
    "                   \n",
    "                    # iterasi fitur data\n",
    "                    # Masukkan data ke input layer\n",
    "                    for l in range(0, len(data[0])):\n",
    "                        neuronList[0][l].add_input(data[k][l])\n",
    "                        # Feed forward tiap layer\n",
    "                        neuronList[0][l].feed_forward()\n",
    "                    \n",
    "                    # iterasi layer\n",
    "                    for l in range(1, self.numLayer):\n",
    "                        \n",
    "                        # iterasi neuron\n",
    "                        for m in range(0, self.numLayer):\n",
    "                            \n",
    "                            # tambahkan input dari layer sebelumnya\n",
    "                            for n in range(len(neuronList[l-1])):\n",
    "                                neuronList[l-1][m].add_input(neuronList[l-1][n].out)\n",
    "                            \n",
    "                            # feed forward neuron\n",
    "                            neuronList[l][m].feed_forward()\n",
    "                    \n",
    "                    # iterasi layer\n",
    "                    for l in range(self.numLayer-1, -1, -1):\n",
    "                        \n",
    "                        # iterasi neuron\n",
    "                        for m in range(0, self.numLayer):\n",
    "                            neuronList[l][m].backpropagation()\n",
    "                            # total local gradient\n",
    "                            lgList[l][m] = lgList[l][m] + neuronList[l][m].localGradient\n",
    "                \n",
    "                # update weight\n",
    "                # iterasi layer\n",
    "                for l in range(0, self.numLayer):\n",
    "                    \n",
    "                    # iterasi neuron\n",
    "                    for m in range(0, )\n",
    "                        neuronList[l][m] = neuronList[l][m]\n",
    "                    \n",
    "                    if (k >= len(data)):\n",
    "                        break\n",
    "                    #print(\"Neuron \", k)\n",
    "                    #for l in range(0, self.inputDim):\n",
    "                        #print(data[k][l])    \n",
    "                print(\"batch finished!\")\n",
    "            print(\"epoch finished!!\")\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def evaluate(self, testData, testTarget):\n",
    "        return None\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def process(self):\n",
    "        \n",
    "        feed_forward()\n",
    "        backward_propagation()\n",
    "        update_weight()\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def feed_forward(self):\n",
    "        return None\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def backward_propagation(self):\n",
    "        return None\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def update_weight(self):\n",
    "        return None\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def sigmoid(self, value):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelas Neuron yang terdiri dari atribut:\n",
    "# 1) local_gradient\n",
    "# 2) index\n",
    "# 3) feed_forward\n",
    "# 4) type menerima enumerasi NeuronType\n",
    "class Neuron:\n",
    "    \n",
    "    local_gradient = 0\n",
    "    value = 0\n",
    "    out = 0\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inputList = []\n",
    "        self.weightList = []\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def feed_forward(self):\n",
    "        print(\"Feed Forward\")\n",
    "        return None\n",
    "        \n",
    "    # Belum Selesai    \n",
    "    def backward_propagation(self):\n",
    "        return None\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def add_input(self, inputValue):\n",
    "        self.inputList.append(inputValue)\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def random_weight(self):\n",
    "        return None\n",
    "    \n",
    "    # Belum Selesai\n",
    "    def reset(self):\n",
    "        self.inputList = []\n",
    "        self.weightList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer[]\n",
    "for i in range(0,len(layer)):\n",
    "    for neuron in layer[i]:\n",
    "        neuron.feed_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffValue[currLayer][idxNeuron] = w[currLayer][i]*ffvalue[prevLayer][i]+bias[idxNeuron]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelas Neuron yang terdiri dari atribut:\n",
    "# 1) local_gradient\n",
    "# 2) index\n",
    "# 3) feed_forward\n",
    "# 4) type menerima enumerasi NeuronType\n",
    "class Neuron:\n",
    "    def __init__(self,input_):\n",
    "        bias = 0\n",
    "        input_val=[]\n",
    "        weight=[]\n",
    "        for i in range(len(input_)):\n",
    "            input_val.append(input_[i])\n",
    "            weight.append(random.random())\n",
    "        output = 0\n",
    "        \n",
    "    def feed_forward(self):\n",
    "        sum_ = bias\n",
    "        for i in range(len(weight)):\n",
    "            sum_ = sum_ + weight[i]*input_val[i]\n",
    "        output = sigmoid(sum_)\n",
    "        return output\n",
    "    \n",
    "    def backward_propagation(self,expected):\n",
    "        #untuk output neuron\n",
    "        derivative = output * (1.0 - output)\n",
    "        error = (expected - output) * derivative\n",
    "        \n",
    "        #untuk hidden layer neuron\n",
    "        \n",
    "        return None\n",
    "    def update_weight(self):\n",
    "        for i in range(len(weight)):\n",
    "            weight[i] = weight[i] + 0.1*error*input_val[i]\n",
    "        return None\n",
    "    \n",
    "    def sigmoid(self, value):\n",
    "        return 1/(1+ math.exp(-value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
